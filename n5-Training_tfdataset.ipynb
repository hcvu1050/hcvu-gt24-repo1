{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train_df      = pd.read_csv ('data/preprocessed_data/G_train.csv')\n",
    "T_train_df      = pd.read_csv ('data/preprocessed_data/T_train.csv')\n",
    "G_T_train_df    = pd.read_csv ('data/preprocessed_data/balanced_G_T_train.csv')\n",
    "\n",
    "G_cv_df         = pd.read_csv ('data/preprocessed_data/G_cv.csv')\n",
    "T_cv_df         = pd.read_csv ('data/preprocessed_data/T_cv.csv')\n",
    "G_T_cv_df        = pd.read_csv ('data/preprocessed_data/G_T_cv.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 13\n",
    "frac = 1\n",
    "\n",
    "G_train_df      = G_train_df.sample(frac = frac, random_state=random_state)\n",
    "T_train_df      = T_train_df.sample(frac = frac, random_state=random_state)\n",
    "G_T_train_df    = G_T_train_df.sample(frac = frac, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128786, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_T_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = G_T_train_df.drop(columns = ['group ID','technique ID' ]).values\n",
    "y_train.dtype\n",
    "\n",
    "# G_train = sampled_G_train_df.drop(columns = ids)\n",
    "G_train = G_train_df.drop(columns = 'group ID').values\n",
    "\n",
    "# T_train = sampled_T_train_df.drop(columns = ids)\n",
    "T_train = T_train_df.drop(columns = 'technique ID').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({'input_Group': G_train_tf, 'input_Technique': T_train_tf}, y_train_tf))\n",
    "```\n",
    "\n",
    "1. `tf.data.Dataset`: This is a class in TensorFlow that represents a potentially large collection of elements. It's used to create pipelines for data processing and input to machine learning models.\n",
    "\n",
    "2. `from_tensor_slices`: This is a method of the `tf.data.Dataset` class. It is used to create a dataset by slicing the given tensors along their first dimension (usually representing the number of samples). This is a convenient way to create a dataset where each element corresponds to a pair of inputs and their corresponding targets.\n",
    "\n",
    "3. `({'input_Group': G_train_tf, 'input_Technique': T_train_tf}, y_train_tf)`: This is a tuple containing two elements. The first element is a dictionary that maps the input tensor names (`'input_Group'` and `'input_Technique'`) to their corresponding tensor data (`G_train_tf` and `T_train_tf`). The second element is the target tensor data `y_train_tf`. ‚ùóThe  names used in the from_tensor_slices dictionary should match the names of the input layers in your model. This ensures that the data from the dataset is correctly mapped to the corresponding input layers during training.\n",
    "\n",
    "\n",
    "So, the overall process of this line of code is to create a dataset where each element is a pair of dictionaries (`{'input_Group': ..., 'input_Technique': ...}`) representing the input tensors and their corresponding target tensor.\n",
    "\n",
    "When you iterate through this dataset, you'll get pairs like:\n",
    "```\n",
    "({'input_Group': G_train_sample, 'input_Technique': T_train_sample}, y_train_sample)\n",
    "```\n",
    "\n",
    "Here, `G_train_sample` and `T_train_sample` are individual samples from your `input_Group` and `input_Technique` tensors, and `y_train_sample` is the corresponding target value for that sample. This dataset structure is suitable for training machine learning models where you have multiple input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train_tf = tf.convert_to_tensor(G_train)\n",
    "T_train_tf = tf.convert_to_tensor(T_train)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({'input_Group': G_train_tf, 'input_Technique': T_train_tf}, y_train_tf))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(G_train_tf))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = G_T_cv_df.drop(columns = ['group ID','technique ID' ]).values\n",
    "y_cv.dtype\n",
    "\n",
    "# G_cv = sampled_G_cv_df.drop(columns = ids)\n",
    "G_cv = G_cv_df.drop(columns = 'group ID').values\n",
    "\n",
    "# T_cv = sampled_T_cv_df.drop(columns = ids)\n",
    "T_cv = T_cv_df.drop(columns = 'technique ID').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cv_tf = tf.convert_to_tensor(G_cv)\n",
    "T_cv_tf = tf.convert_to_tensor(T_cv)\n",
    "y_cv_tf = tf.convert_to_tensor(y_cv)\n",
    "cv_dataset = tf.data.Dataset.from_tensor_slices(({'input_Group': G_cv_tf, 'input_Technique': T_cv_tf}, y_cv_tf))\n",
    "cv_dataset = cv_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shapes config\n",
    "num_G_features = G_train.shape[1]  # remove Group ID during training\n",
    "num_T_features = T_train.shape[1]   # remove Movie ID during training\n",
    "\n",
    "# output\n",
    "num_outputs = 32\n",
    "\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "# Group NN\n",
    "Group_NN = tf.keras.models.Sequential(\n",
    "    layers=[\n",
    "    tf.keras.layers.Dense (256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (num_outputs, activation  = 'linear'),\n",
    "    ], \n",
    "    name= \"Group_NN\")\n",
    "# input vector for user_NN\n",
    "input_Group = tf.keras.layers.Input(shape = (num_G_features), name = \"input_Group\")\n",
    "vg = Group_NN(input_Group)\n",
    "# vg = tf.linalg.l2_normalize(vg, axis=1)\n",
    "\n",
    "# Technique NN\n",
    "Technique_NN = tf.keras.models.Sequential(\n",
    "    layers = [\n",
    "    tf.keras.layers.Dense (256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense (num_outputs, activation  = 'linear'),  \n",
    "    ],\n",
    "    name = \"Technique_NN\")\n",
    "# input vector for Technique_NN\n",
    "input_Technique = tf.keras.layers.Input (shape= (num_T_features), name = \"input_Technique\")\n",
    "vt = Technique_NN (input_Technique)\n",
    "# vt = tf.linalg.l2_normalize (vt, axis = 1)\n",
    "\n",
    "output = tf.keras.layers.Dot (axes=1)(inputs= [vg, vt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(random_state)\n",
    "opt = keras.optimizers.Adam (learning_rate= 0.05)\n",
    "model = tf.keras.Model (inputs = [input_Group, input_Technique],\n",
    "                        outputs = output, name = 'recsysNN_model')\n",
    "model.compile (optimizer = opt, loss = BinaryCrossentropy (from_logits= True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss for early stopping\n",
    "    patience=32,           # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best validation loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.7559 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6942 - val_loss: 0.6434\n",
      "Epoch 3/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6949 - val_loss: 0.6944\n",
      "Epoch 4/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6951 - val_loss: 0.6963\n",
      "Epoch 5/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6951 - val_loss: 0.7370\n",
      "Epoch 6/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6951 - val_loss: 0.6717\n",
      "Epoch 7/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6948 - val_loss: 0.5160\n",
      "Epoch 8/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6952 - val_loss: 0.6977\n",
      "Epoch 9/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6948 - val_loss: 0.7600\n",
      "Epoch 10/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6952 - val_loss: 0.6728\n",
      "Epoch 11/100\n",
      "4025/4025 [==============================] - 20s 5ms/step - loss: 0.6950 - val_loss: 0.6290\n",
      "Epoch 12/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6951 - val_loss: 0.7198\n",
      "Epoch 13/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6953 - val_loss: 0.6606\n",
      "Epoch 14/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6947 - val_loss: 0.7888\n",
      "Epoch 15/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6952 - val_loss: 0.7290\n",
      "Epoch 16/100\n",
      "4025/4025 [==============================] - 22s 5ms/step - loss: 0.6952 - val_loss: 0.6946\n",
      "Epoch 17/100\n",
      "4025/4025 [==============================] - 22s 5ms/step - loss: 0.6949 - val_loss: 0.7027\n",
      "Epoch 18/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6950 - val_loss: 0.7109\n",
      "Epoch 19/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6955 - val_loss: 0.7048\n",
      "Epoch 20/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6952 - val_loss: 0.7507\n",
      "Epoch 21/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6955 - val_loss: 0.6899\n",
      "Epoch 22/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6952 - val_loss: 0.6930\n",
      "Epoch 23/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6949 - val_loss: 0.6197\n",
      "Epoch 24/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6954 - val_loss: 0.7429\n",
      "Epoch 25/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6952 - val_loss: 0.6771\n",
      "Epoch 26/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6948 - val_loss: 0.7004\n",
      "Epoch 27/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6948 - val_loss: 0.7422\n",
      "Epoch 28/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6950 - val_loss: 0.6932\n",
      "Epoch 29/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6955 - val_loss: 0.8112\n",
      "Epoch 30/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6948 - val_loss: 0.6562\n",
      "Epoch 31/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6949 - val_loss: 0.6963\n",
      "Epoch 32/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6957 - val_loss: 0.6930\n",
      "Epoch 33/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6949 - val_loss: 0.6387\n",
      "Epoch 34/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6948 - val_loss: 0.6847\n",
      "Epoch 35/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6955 - val_loss: 0.6872\n",
      "Epoch 36/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6950 - val_loss: 0.6934\n",
      "Epoch 37/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6948 - val_loss: 0.6920\n",
      "Epoch 38/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6950 - val_loss: 0.6836\n",
      "Epoch 39/100\n",
      "4025/4025 [==============================] - 21s 5ms/step - loss: 0.6950 - val_loss: 0.6765\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data = cv_dataset,\n",
    "                    epochs = epochs,\n",
    "                    callbacks = [early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "training_loss_file = 'training_loss.csv'\n",
    "validation_loss_file = 'validation_loss.csv'\n",
    "\n",
    "with open(training_loss_file, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(training_loss)\n",
    "\n",
    "with open(validation_loss_file, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(training_loss))\n",
    "print(len(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7559331059455872, 0.694195032119751, 0.6949310898780823, 0.6951173543930054, 0.695149838924408, 0.6950742602348328, 0.6947999000549316, 0.695155143737793, 0.6947545409202576, 0.6951875686645508, 0.694950520992279, 0.6951336860656738, 0.6952548027038574, 0.6947100758552551, 0.6951882243156433, 0.6951568722724915, 0.6948810815811157, 0.6949570178985596, 0.6954952478408813, 0.6951717138290405, 0.695451557636261, 0.6951914429664612, 0.6948603391647339, 0.695415198802948, 0.695213258266449, 0.6948020458221436, 0.694820761680603, 0.6949731111526489, 0.695512592792511, 0.6948270797729492, 0.6948840618133545, 0.6956643462181091, 0.694923460483551, 0.694814145565033, 0.695465087890625, 0.6949814558029175, 0.6948235630989075, 0.6950023770332336, 0.6950470805168152]\n",
      "[0.6931461095809937, 0.6433700919151306, 0.6943687200546265, 0.6962643265724182, 0.7369785308837891, 0.6716542840003967, 0.5160380005836487, 0.6976915001869202, 0.7600456476211548, 0.6728299856185913, 0.6289705634117126, 0.7198359966278076, 0.660603404045105, 0.7888190746307373, 0.7289594411849976, 0.6946027874946594, 0.7027031779289246, 0.7108585834503174, 0.7048274874687195, 0.7506957054138184, 0.6899065375328064, 0.6929890513420105, 0.619723379611969, 0.7429121136665344, 0.6771446466445923, 0.700373649597168, 0.7421501278877258, 0.6932119727134705, 0.8112394213676453, 0.656184732913971, 0.696297287940979, 0.6930127143859863, 0.6386532187461853, 0.684694766998291, 0.6871858835220337, 0.6934475302696228, 0.6919982433319092, 0.6836183071136475, 0.676460862159729]\n"
     ]
    }
   ],
   "source": [
    "print (training_loss)\n",
    "print (validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "# plt.plot(range(1, len(training_loss) + 1), training_loss, label='Training Loss')\n",
    "# plt.plot(range(1, len(validation_loss) + 1), validation_loss, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, len(training_loss) + 1), training_loss, label='Training Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfNote01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
